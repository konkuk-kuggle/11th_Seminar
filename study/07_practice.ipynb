{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.깔끔한 데이터"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 07-1 열과 피벗"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             religion  <$10k  $10-20k  $20-30k  $30-40k  $40-50k  $50-75k  \\\n",
      "0            Agnostic     27       34       60       81       76      137   \n",
      "1             Atheist     12       27       37       52       35       70   \n",
      "2            Buddhist     27       21       30       34       33       58   \n",
      "3            Catholic    418      617      732      670      638     1116   \n",
      "4  Don’t know/refused     15       14       15       11       10       35   \n",
      "\n",
      "   $75-100k  $100-150k  >150k  Don't know/refused  \n",
      "0       122        109     84                  96  \n",
      "1        73         59     74                  76  \n",
      "2        62         39     53                  54  \n",
      "3       949        792    633                1489  \n",
      "4        21         17     18                 116  \n"
     ]
    }
   ],
   "source": [
    "#melt 사용하기\n",
    "\n",
    "#1개의 열만 고정하고 나머지 열을 행으로 바꾸기\n",
    "import pandas as pd\n",
    "pew = pd.read_csv('../data/pew.csv')\n",
    "print(pew.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   religion  <$10k  $10-20k  $20-30k  $30-40k  $40-50k\n",
      "0                  Agnostic     27       34       60       81       76\n",
      "1                   Atheist     12       27       37       52       35\n",
      "2                  Buddhist     27       21       30       34       33\n",
      "3                  Catholic    418      617      732      670      638\n",
      "4        Don’t know/refused     15       14       15       11       10\n",
      "5          Evangelical Prot    575      869     1064      982      881\n",
      "6                     Hindu      1        9        7        9       11\n",
      "7   Historically Black Prot    228      244      236      238      197\n",
      "8         Jehovah's Witness     20       27       24       24       21\n",
      "9                    Jewish     19       19       25       25       30\n",
      "10            Mainline Prot    289      495      619      655      651\n",
      "11                   Mormon     29       40       48       51       56\n",
      "12                   Muslim      6        7        9       10        9\n",
      "13                 Orthodox     13       17       23       32       32\n",
      "14          Other Christian      9        7       11       13       13\n",
      "15             Other Faiths     20       33       40       46       49\n",
      "16    Other World Religions      5        2        3        4        2\n",
      "17             Unaffiliated    217      299      374      365      341\n"
     ]
    }
   ],
   "source": [
    "print(pew.iloc[:, 0:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             religion variable  value\n",
      "0            Agnostic    <$10k     27\n",
      "1             Atheist    <$10k     12\n",
      "2            Buddhist    <$10k     27\n",
      "3            Catholic    <$10k    418\n",
      "4  Don’t know/refused    <$10k     15\n"
     ]
    }
   ],
   "source": [
    "pew_long = pd.melt(pew, id_vars='religion')\n",
    "print(pew_long.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             religion income  count\n",
      "0            Agnostic  <$10k     27\n",
      "1             Atheist  <$10k     12\n",
      "2            Buddhist  <$10k     27\n",
      "3            Catholic  <$10k    418\n",
      "4  Don’t know/refused  <$10k     15\n"
     ]
    }
   ],
   "source": [
    "#열 이름 바꾸기\n",
    "pew_long = pd.melt(pew, id_vars='religion', var_name='income', value_name='count')\n",
    "print(pew_long.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   year        artist                    track  time date.entered  wk1   wk2  \\\n",
      "0  2000         2 Pac  Baby Don't Cry (Keep...  4:22   2000-02-26   87  82.0   \n",
      "1  2000       2Ge+her  The Hardest Part Of ...  3:15   2000-09-02   91  87.0   \n",
      "2  2000  3 Doors Down               Kryptonite  3:53   2000-04-08   81  70.0   \n",
      "3  2000  3 Doors Down                    Loser  4:24   2000-10-21   76  76.0   \n",
      "4  2000      504 Boyz            Wobble Wobble  3:35   2000-04-15   57  34.0   \n",
      "\n",
      "    wk3   wk4   wk5   wk6   wk7   wk8   wk9  wk10  wk11  \n",
      "0  72.0  77.0  87.0  94.0  99.0   NaN   NaN   NaN   NaN  \n",
      "1  92.0   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "2  68.0  67.0  66.0  57.0  54.0  53.0  51.0  51.0  51.0  \n",
      "3  72.0  69.0  67.0  65.0  55.0  59.0  62.0  61.0  61.0  \n",
      "4  25.0  17.0  17.0  31.0  36.0  49.0  53.0  57.0  64.0  \n"
     ]
    }
   ],
   "source": [
    "# 2개 이상의 열을 고정하고 나머지 열을 행으로 바꾸기\n",
    "billboard = pd.read_csv('../data/billboard.csv')\n",
    "print(billboard.iloc[0:5, 0:16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   year        artist                    track  time date.entered week  rating\n",
      "0  2000         2 Pac  Baby Don't Cry (Keep...  4:22   2000-02-26  wk1    87.0\n",
      "1  2000       2Ge+her  The Hardest Part Of ...  3:15   2000-09-02  wk1    91.0\n",
      "2  2000  3 Doors Down               Kryptonite  3:53   2000-04-08  wk1    81.0\n",
      "3  2000  3 Doors Down                    Loser  4:24   2000-10-21  wk1    76.0\n",
      "4  2000      504 Boyz            Wobble Wobble  3:35   2000-04-15  wk1    57.0\n"
     ]
    }
   ],
   "source": [
    "billboard_long = pd.melt(billboard, id_vars=['year', 'artist', 'track', 'time', 'date.entered'], var_name='week', value_name='rating')\n",
    "print(billboard_long.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 07-2 열 이름 관리하기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Date', 'Day', 'Cases_Guinea', 'Cases_Liberia', 'Cases_SierraLeone',\n",
      "       'Cases_Nigeria', 'Cases_Senegal', 'Cases_UnitedStates', 'Cases_Spain',\n",
      "       'Cases_Mali', 'Deaths_Guinea', 'Deaths_Liberia', 'Deaths_SierraLeone',\n",
      "       'Deaths_Nigeria', 'Deaths_Senegal', 'Deaths_UnitedStates',\n",
      "       'Deaths_Spain', 'Deaths_Mali'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#하나의 열이 여러 의미를 가지고 있는 경우\n",
    "\n",
    "#ebola 데이터 확인\n",
    "ebola = pd.read_csv('../data/country_timeseries.csv')\n",
    "print(ebola.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date  Day  Cases_Guinea  Cases_Liberia  Deaths_Guinea  Deaths_Liberia\n",
      "0    1/5/2015  289        2776.0            NaN         1786.0             NaN\n",
      "1    1/4/2015  288        2775.0            NaN         1781.0             NaN\n",
      "2    1/3/2015  287        2769.0         8166.0         1767.0          3496.0\n",
      "3    1/2/2015  286           NaN         8157.0            NaN          3496.0\n",
      "4  12/31/2014  284        2730.0         8115.0         1739.0          3471.0\n"
     ]
    }
   ],
   "source": [
    "print(ebola.iloc[:5, [0, 1, 2, 3, 10, 11]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date  Day      variable   value\n",
      "0    1/5/2015  289  Cases_Guinea  2776.0\n",
      "1    1/4/2015  288  Cases_Guinea  2775.0\n",
      "2    1/3/2015  287  Cases_Guinea  2769.0\n",
      "3    1/2/2015  286  Cases_Guinea     NaN\n",
      "4  12/31/2014  284  Cases_Guinea  2730.0\n"
     ]
    }
   ],
   "source": [
    "#원하는 두 열을 고정하기\n",
    "ebola_long = pd.melt(ebola, id_vars=['Date', 'Day'])\n",
    "print(ebola_long.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    [Cases, Guinea]\n",
      "1    [Cases, Guinea]\n",
      "2    [Cases, Guinea]\n",
      "3    [Cases, Guinea]\n",
      "4    [Cases, Guinea]\n",
      "Name: variable, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#열 이름 분리하고 데이터프레임에 추가하기\n",
    "\n",
    "#split으로 분리하기\n",
    "variable_split = ebola_long.variable.str.split('_')\n",
    "print(variable_split[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'> <class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(type(variable_split), type(variable_split[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    Cases\n",
      "1    Cases\n",
      "2    Cases\n",
      "3    Cases\n",
      "4    Cases\n",
      "Name: variable, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#get을 사용하여 0,1번째 인덱스의 데이터 한번에 추출하기\n",
    "status_values = variable_split.str.get(0) \n",
    "country_values = variable_split.str.get(1)\n",
    "print(status_values[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1947    Deaths\n",
      "1948    Deaths\n",
      "1949    Deaths\n",
      "1950    Deaths\n",
      "1951    Deaths\n",
      "Name: variable, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(status_values[-5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    Guinea\n",
      "1    Guinea\n",
      "2    Guinea\n",
      "3    Guinea\n",
      "4    Guinea\n",
      "Name: variable, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(country_values[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1947    Mali\n",
      "1948    Mali\n",
      "1949    Mali\n",
      "1950    Mali\n",
      "1951    Mali\n",
      "Name: variable, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(country_values[-5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date  Day      variable   value status country\n",
      "0    1/5/2015  289  Cases_Guinea  2776.0  Cases  Guinea\n",
      "1    1/4/2015  288  Cases_Guinea  2775.0  Cases  Guinea\n",
      "2    1/3/2015  287  Cases_Guinea  2769.0  Cases  Guinea\n",
      "3    1/2/2015  286  Cases_Guinea     NaN  Cases  Guinea\n",
      "4  12/31/2014  284  Cases_Guinea  2730.0  Cases  Guinea\n"
     ]
    }
   ],
   "source": [
    "#분리한 문자열을 각각의 이름으로 데이터프레임에 추가하기\n",
    "ebola_long['status'] = status_values \n",
    "ebola_long['country'] = country_values\n",
    "print(ebola_long.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date  Day      variable   value status country status country\n",
      "0    1/5/2015  289  Cases_Guinea  2776.0  Cases  Guinea  Cases  Guinea\n",
      "1    1/4/2015  288  Cases_Guinea  2775.0  Cases  Guinea  Cases  Guinea\n",
      "2    1/3/2015  287  Cases_Guinea  2769.0  Cases  Guinea  Cases  Guinea\n",
      "3    1/2/2015  286  Cases_Guinea     NaN  Cases  Guinea  Cases  Guinea\n",
      "4  12/31/2014  284  Cases_Guinea  2730.0  Cases  Guinea  Cases  Guinea\n"
     ]
    }
   ],
   "source": [
    "#concat으로 데이터프레임에 열 추가하기\n",
    "variable_split = ebola_long.variable.str.split('_', expand=True) \n",
    "variable_split.columns = ['status', 'country'] \n",
    "ebola_parsed = pd.concat([ebola_long, variable_split], axis=1)\n",
    "print(ebola_parsed.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 07-3 여러 열을 하나로 정리하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id  year  month element  d1    d2    d3  d4    d5  d6  d7\n",
      "0  MX17004  2010      1    tmax NaN   NaN   NaN NaN   NaN NaN NaN\n",
      "1  MX17004  2010      1    tmin NaN   NaN   NaN NaN   NaN NaN NaN\n",
      "2  MX17004  2010      2    tmax NaN  27.3  24.1 NaN   NaN NaN NaN\n",
      "3  MX17004  2010      2    tmin NaN  14.4  14.4 NaN   NaN NaN NaN\n",
      "4  MX17004  2010      3    tmax NaN   NaN   NaN NaN  32.1 NaN NaN\n"
     ]
    }
   ],
   "source": [
    "#열을 행 데이터로 피벗\n",
    "weather = pd.read_csv('../data/weather.csv') \n",
    "print(weather.iloc[:5, :11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id  year  month element day  temp\n",
      "0  MX17004  2010      1    tmax  d1   NaN\n",
      "1  MX17004  2010      1    tmin  d1   NaN\n",
      "2  MX17004  2010      2    tmax  d1   NaN\n",
      "3  MX17004  2010      2    tmin  d1   NaN\n",
      "4  MX17004  2010      3    tmax  d1   NaN\n"
     ]
    }
   ],
   "source": [
    "#melt로 일별 온도 측정값 피벗\n",
    "weather_melt = pd.melt(weather, id_vars=['id', 'year', 'month', 'element'], var_name='day', value_name='temp') \n",
    "print(weather_melt.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "element                 tmax  tmin\n",
      "id      year month day            \n",
      "MX17004 2010 1     d30  27.8  14.5\n",
      "             2     d11  29.7  13.4\n",
      "                   d2   27.3  14.4\n",
      "                   d23  29.9  10.7\n",
      "                   d3   24.1  14.4\n",
      "             3     d10  34.5  16.8\n",
      "                   d16  31.1  17.6\n",
      "                   d5   32.1  14.2\n",
      "             4     d27  36.3  16.7\n",
      "             5     d27  33.2  18.2\n",
      "             6     d17  28.0  17.5\n",
      "                   d29  30.1  18.0\n",
      "             7     d3   28.6  17.5\n",
      "                   d14  29.9  16.5\n",
      "             8     d23  26.4  15.0\n",
      "                   d5   29.6  15.8\n",
      "                   d29  28.0  15.3\n",
      "                   d13  29.8  16.5\n",
      "                   d25  29.7  15.6\n",
      "                   d31  25.4  15.4\n",
      "                   d8   29.0  17.3\n",
      "             10    d5   27.0  14.0\n",
      "                   d14  29.5  13.0\n",
      "                   d15  28.7  10.5\n",
      "                   d28  31.2  15.0\n",
      "                   d7   28.1  12.9\n",
      "             11    d2   31.3  16.3\n",
      "                   d5   26.3   7.9\n",
      "                   d27  27.7  14.2\n",
      "                   d26  28.1  12.1\n",
      "                   d4   27.2  12.0\n",
      "             12    d1   29.9  13.8\n",
      "                   d6   27.8  10.5\n"
     ]
    }
   ],
   "source": [
    "#pivot_table 사용하여 행과 열 위치 바꾸기\n",
    "weather_tidy = weather_melt.pivot_table(\n",
    "    index=['id', 'year', 'month', 'day'], \n",
    "    columns='element', \n",
    "    values='temp'\n",
    ")\n",
    "\n",
    "print(weather_tidy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "element       id  year  month  day  tmax  tmin\n",
      "0        MX17004  2010      1  d30  27.8  14.5\n",
      "1        MX17004  2010      2  d11  29.7  13.4\n",
      "2        MX17004  2010      2   d2  27.3  14.4\n",
      "3        MX17004  2010      2  d23  29.9  10.7\n",
      "4        MX17004  2010      2   d3  24.1  14.4\n"
     ]
    }
   ],
   "source": [
    "#reset_index로 데이터프레임 인덱스 새로 지정\n",
    "weather_tidy_flat = weather_tidy.reset_index() \n",
    "print(weather_tidy_flat.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 07-4 중복 데이터 처리하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24092, 7)\n",
      "   year        artist                    track  time date.entered week  rating\n",
      "0  2000         2 Pac  Baby Don't Cry (Keep...  4:22   2000-02-26  wk1    87.0\n",
      "1  2000       2Ge+her  The Hardest Part Of ...  3:15   2000-09-02  wk1    91.0\n",
      "2  2000  3 Doors Down               Kryptonite  3:53   2000-04-08  wk1    81.0\n",
      "3  2000  3 Doors Down                    Loser  4:24   2000-10-21  wk1    76.0\n",
      "4  2000      504 Boyz            Wobble Wobble  3:35   2000-04-15  wk1    57.0\n"
     ]
    }
   ],
   "source": [
    "#데이터 불러오기\n",
    "billboard = pd.read_csv('../data/billboard.csv')\n",
    "billboard_long = pd.melt(billboard, id_vars=['year', 'artist', 'track', 'time', 'date.entered'], var_name='week', value_name='rating')\n",
    "\n",
    "print(billboard_long.shape)\n",
    "\n",
    "print(billboard_long.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      year        artist  track  time date.entered week  rating\n",
      "3     2000  3 Doors Down  Loser  4:24   2000-10-21  wk1    76.0\n",
      "320   2000  3 Doors Down  Loser  4:24   2000-10-21  wk2    76.0\n",
      "637   2000  3 Doors Down  Loser  4:24   2000-10-21  wk3    72.0\n",
      "954   2000  3 Doors Down  Loser  4:24   2000-10-21  wk4    69.0\n",
      "1271  2000  3 Doors Down  Loser  4:24   2000-10-21  wk5    67.0\n"
     ]
    }
   ],
   "source": [
    "#중복 데이터 확인하기\n",
    "print(billboard_long[billboard_long.track == 'Loser'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24092, 4)\n"
     ]
    }
   ],
   "source": [
    "#중복 데이터가 있는 열을 모아 새로운 데이터프레임에 저장\n",
    "billboard_songs = billboard_long[['year', 'artist', 'track', 'time']] \n",
    "print(billboard_songs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(317, 4)\n"
     ]
    }
   ],
   "source": [
    "#drop_duplicates로 중복 데이터 제거\n",
    "billboard_songs = billboard_songs.drop_duplicates() \n",
    "print(billboard_songs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   year          artist                    track  time  id\n",
      "0  2000           2 Pac  Baby Don't Cry (Keep...  4:22   0\n",
      "1  2000         2Ge+her  The Hardest Part Of ...  3:15   1\n",
      "2  2000    3 Doors Down               Kryptonite  3:53   2\n",
      "3  2000    3 Doors Down                    Loser  4:24   3\n",
      "4  2000        504 Boyz            Wobble Wobble  3:35   4\n",
      "5  2000            98^0  Give Me Just One Nig...  3:24   5\n",
      "6  2000         A*Teens            Dancing Queen  3:44   6\n",
      "7  2000         Aaliyah            I Don't Wanna  4:15   7\n",
      "8  2000         Aaliyah                Try Again  4:03   8\n",
      "9  2000  Adams, Yolanda            Open My Heart  5:30   9\n"
     ]
    }
   ],
   "source": [
    "#아이디 추가\n",
    "billboard_songs['id'] = range(len(billboard_songs)) \n",
    "print(billboard_songs.head(n=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24092, 8)\n",
      "   year        artist                    track  time date.entered week  \\\n",
      "0  2000         2 Pac  Baby Don't Cry (Keep...  4:22   2000-02-26  wk1   \n",
      "1  2000       2Ge+her  The Hardest Part Of ...  3:15   2000-09-02  wk1   \n",
      "2  2000  3 Doors Down               Kryptonite  3:53   2000-04-08  wk1   \n",
      "3  2000  3 Doors Down                    Loser  4:24   2000-10-21  wk1   \n",
      "4  2000      504 Boyz            Wobble Wobble  3:35   2000-04-15  wk1   \n",
      "\n",
      "   rating  id  \n",
      "0    87.0   0  \n",
      "1    91.0   1  \n",
      "2    81.0   2  \n",
      "3    76.0   3  \n",
      "4    57.0   4  \n"
     ]
    }
   ],
   "source": [
    "#merge를 사용해 노래정보와 순위 데이터 합치기\n",
    "billboard_ratings = billboard_long.merge( billboard_songs, on=['year', 'artist', 'track', 'time']) \n",
    "print(billboard_ratings.shape)\n",
    "\n",
    "print(billboard_ratings.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 07-5 대용량 데이터 처리하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://s3.amazonaws.com/nyc-tlc/trip+data/fhv_tripdata_2015-01.csv\n",
      "\n",
      "../data/fhv_tripdata_2015-01.csv\n"
     ]
    },
    {
     "ename": "HTTPError",
     "evalue": "HTTP Error 403: Forbidden",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[64], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(url)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(fp)\n\u001b[0;32m---> 13\u001b[0m urllib\u001b[38;5;241m.\u001b[39mrequest\u001b[38;5;241m.\u001b[39murlretrieve(url, fp)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/urllib/request.py:240\u001b[0m, in \u001b[0;36murlretrieve\u001b[0;34m(url, filename, reporthook, data)\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;124;03mRetrieve a URL into a temporary location on disk.\u001b[39;00m\n\u001b[1;32m    225\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;124;03mdata file as well as the resulting HTTPMessage object.\u001b[39;00m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    238\u001b[0m url_type, path \u001b[38;5;241m=\u001b[39m _splittype(url)\n\u001b[0;32m--> 240\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m contextlib\u001b[38;5;241m.\u001b[39mclosing(urlopen(url, data)) \u001b[38;5;28;01mas\u001b[39;00m fp:\n\u001b[1;32m    241\u001b[0m     headers \u001b[38;5;241m=\u001b[39m fp\u001b[38;5;241m.\u001b[39minfo()\n\u001b[1;32m    243\u001b[0m     \u001b[38;5;66;03m# Just return the local path and the \"headers\" for file://\u001b[39;00m\n\u001b[1;32m    244\u001b[0m     \u001b[38;5;66;03m# URLs. No sense in performing a copy unless requested.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/urllib/request.py:215\u001b[0m, in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    214\u001b[0m     opener \u001b[38;5;241m=\u001b[39m _opener\n\u001b[0;32m--> 215\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m opener\u001b[38;5;241m.\u001b[39mopen(url, data, timeout)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/urllib/request.py:521\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    519\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m processor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_response\u001b[38;5;241m.\u001b[39mget(protocol, []):\n\u001b[1;32m    520\u001b[0m     meth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(processor, meth_name)\n\u001b[0;32m--> 521\u001b[0m     response \u001b[38;5;241m=\u001b[39m meth(req, response)\n\u001b[1;32m    523\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/urllib/request.py:630\u001b[0m, in \u001b[0;36mHTTPErrorProcessor.http_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;66;03m# According to RFC 2616, \"2xx\" code indicates that the client's\u001b[39;00m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;66;03m# request was successfully received, understood, and accepted.\u001b[39;00m\n\u001b[1;32m    629\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m code \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m):\n\u001b[0;32m--> 630\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparent\u001b[38;5;241m.\u001b[39merror(\n\u001b[1;32m    631\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttp\u001b[39m\u001b[38;5;124m'\u001b[39m, request, response, code, msg, hdrs)\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/urllib/request.py:559\u001b[0m, in \u001b[0;36mOpenerDirector.error\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    557\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_err:\n\u001b[1;32m    558\u001b[0m     args \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mdict\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttp_error_default\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m+\u001b[39m orig_args\n\u001b[0;32m--> 559\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_chain(\u001b[38;5;241m*\u001b[39margs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/urllib/request.py:492\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    490\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[1;32m    491\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[0;32m--> 492\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m    493\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    494\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/urllib/request.py:639\u001b[0m, in \u001b[0;36mHTTPDefaultErrorHandler.http_error_default\u001b[0;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[1;32m    638\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhttp_error_default\u001b[39m(\u001b[38;5;28mself\u001b[39m, req, fp, code, msg, hdrs):\n\u001b[0;32m--> 639\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(req\u001b[38;5;241m.\u001b[39mfull_url, code, msg, hdrs, fp)\n",
      "\u001b[0;31mHTTPError\u001b[0m: HTTP Error 403: Forbidden"
     ]
    }
   ],
   "source": [
    "#데이터 내려받기(안받아짐ㅠ)\n",
    "import os \n",
    "import urllib.request\n",
    "\n",
    "with open('../data/raw_data_urls.txt', 'r') as data_urls:\n",
    "    for line, url in enumerate(data_urls):\n",
    "        if line == 5:\n",
    "            break \n",
    "        fn = url.split('/')[-1].strip()\n",
    "        fp = os.path.join('', '../data', fn)\n",
    "        print(url)\n",
    "        print(fp)\n",
    "        urllib.request.urlretrieve(url, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "#glob로 데이터 불러오기\n",
    "import glob \n",
    "nyc_taxi_data = glob.glob('../data/fhv_*') \n",
    "print(nyc_taxi_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[68], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#각각의 파일 데이터프레임 지정하기\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m taxi1 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(nyc_taxi_data[\u001b[38;5;241m0\u001b[39m]) \n\u001b[1;32m      3\u001b[0m taxi2 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(nyc_taxi_data[\u001b[38;5;241m1\u001b[39m]) \n\u001b[1;32m      4\u001b[0m taxi3 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(nyc_taxi_data[\u001b[38;5;241m2\u001b[39m]) \n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "#각각의 파일 데이터프레임 지정하기\n",
    "taxi1 = pd.read_csv(nyc_taxi_data[0]) \n",
    "taxi2 = pd.read_csv(nyc_taxi_data[1]) \n",
    "taxi3 = pd.read_csv(nyc_taxi_data[2]) \n",
    "taxi4 = pd.read_csv(nyc_taxi_data[3]) \n",
    "taxi5 = pd.read_csv(nyc_taxi_data[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'taxi1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[70], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#데이터 확인하기\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(taxi1\u001b[38;5;241m.\u001b[39mhead(n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)) \n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(taxi2\u001b[38;5;241m.\u001b[39mhead(n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)) \n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(taxi3\u001b[38;5;241m.\u001b[39mhead(n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)) \n",
      "\u001b[0;31mNameError\u001b[0m: name 'taxi1' is not defined"
     ]
    }
   ],
   "source": [
    "#데이터 확인하기\n",
    "print(taxi1.head(n=2)) \n",
    "print(taxi2.head(n=2)) \n",
    "print(taxi3.head(n=2)) \n",
    "print(taxi4.head(n=2)) \n",
    "print(taxi5.head(n=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'taxi1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[72], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#데이터 구조 확인하기\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(taxi1\u001b[38;5;241m.\u001b[39mshape) \n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(taxi2\u001b[38;5;241m.\u001b[39mshape) \n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(taxi3\u001b[38;5;241m.\u001b[39mshape) \n",
      "\u001b[0;31mNameError\u001b[0m: name 'taxi1' is not defined"
     ]
    }
   ],
   "source": [
    "#데이터 구조 확인하기\n",
    "print(taxi1.shape) \n",
    "print(taxi2.shape) \n",
    "print(taxi3.shape) \n",
    "print(taxi4.shape) \n",
    "print(taxi5.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'taxi1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[74], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#각 데이터프레임 연결하기\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m taxi \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([taxi1, taxi2, taxi3, taxi4, taxi5])\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(taxi\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'taxi1' is not defined"
     ]
    }
   ],
   "source": [
    "#각 데이터프레임 연결하기\n",
    "taxi = pd.concat([taxi1, taxi2, taxi3, taxi4, taxi5])\n",
    "\n",
    "print(taxi.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[76], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m     list_taxi_df\u001b[38;5;241m.\u001b[39mappend(df) \n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(list_taxi_df))\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mtype\u001b[39m(list_taxi_df[\u001b[38;5;241m0\u001b[39m]))\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "#반복문으로 데이터 준비하기\n",
    "list_taxi_df = [] \n",
    "\n",
    "for csv_filename in nyc_taxi_data:\n",
    "    # print(csv_filename)\n",
    "    df = pd.read_csv(csv_filename)\n",
    "    list_taxi_df.append(df) \n",
    "\n",
    "print(len(list_taxi_df))\n",
    "print(type(list_taxi_df[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No objects to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[78], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m taxi_loop_concat \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat(list_taxi_df) \n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(taxi_loop_concat\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/reshape/concat.py:382\u001b[0m, in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m copy \u001b[38;5;129;01mand\u001b[39;00m using_copy_on_write():\n\u001b[1;32m    380\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 382\u001b[0m op \u001b[38;5;241m=\u001b[39m _Concatenator(\n\u001b[1;32m    383\u001b[0m     objs,\n\u001b[1;32m    384\u001b[0m     axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[1;32m    385\u001b[0m     ignore_index\u001b[38;5;241m=\u001b[39mignore_index,\n\u001b[1;32m    386\u001b[0m     join\u001b[38;5;241m=\u001b[39mjoin,\n\u001b[1;32m    387\u001b[0m     keys\u001b[38;5;241m=\u001b[39mkeys,\n\u001b[1;32m    388\u001b[0m     levels\u001b[38;5;241m=\u001b[39mlevels,\n\u001b[1;32m    389\u001b[0m     names\u001b[38;5;241m=\u001b[39mnames,\n\u001b[1;32m    390\u001b[0m     verify_integrity\u001b[38;5;241m=\u001b[39mverify_integrity,\n\u001b[1;32m    391\u001b[0m     copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[1;32m    392\u001b[0m     sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[1;32m    393\u001b[0m )\n\u001b[1;32m    395\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/reshape/concat.py:445\u001b[0m, in \u001b[0;36m_Concatenator.__init__\u001b[0;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[1;32m    442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverify_integrity \u001b[38;5;241m=\u001b[39m verify_integrity\n\u001b[1;32m    443\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy \u001b[38;5;241m=\u001b[39m copy\n\u001b[0;32m--> 445\u001b[0m objs, keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clean_keys_and_objs(objs, keys)\n\u001b[1;32m    447\u001b[0m \u001b[38;5;66;03m# figure out what our result ndim is going to be\u001b[39;00m\n\u001b[1;32m    448\u001b[0m ndims \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_ndims(objs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/reshape/concat.py:507\u001b[0m, in \u001b[0;36m_Concatenator._clean_keys_and_objs\u001b[0;34m(self, objs, keys)\u001b[0m\n\u001b[1;32m    504\u001b[0m     objs_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(objs)\n\u001b[1;32m    506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(objs_list) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 507\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo objects to concatenate\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    509\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keys \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    510\u001b[0m     objs_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(com\u001b[38;5;241m.\u001b[39mnot_none(\u001b[38;5;241m*\u001b[39mobjs_list))\n",
      "\u001b[0;31mValueError\u001b[0m: No objects to concatenate"
     ]
    }
   ],
   "source": [
    "taxi_loop_concat = pd.concat(list_taxi_df) \n",
    "print(taxi_loop_concat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'taxi' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[80], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(taxi\u001b[38;5;241m.\u001b[39mequals(taxi_loop_concat))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'taxi' is not defined"
     ]
    }
   ],
   "source": [
    "print(taxi.equals(taxi_loop_concat))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
